\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{setspace}
\usepackage{longtable}
\usepackage{array}
\onehalfspacing
\setlength{\emergencystretch}{2em}

\title{Silicon Stratigraphy:\\Preserving Digital Layers in AI-Assisted Archaeological Research}
\author{Scott J. Boudreaux\\Elyan Labs, Louisiana, USA\\\texttt{scott@elyanlabs.ai}}
\date{February 2026}

\begin{document}
\maketitle

\begin{abstract}
Archaeologists today routinely work with thousands of born-digital excavation reports and open museum collections. Yet every time we ask an AI tool to summarize or interpret these data, the digital equivalent of stratigraphic layers can be erased: we can no longer tell which sentence came from which original source, when it was created, or whether it has been altered. This paper introduces \textit{Silicon Stratigraphy}, a lightweight provenance-first workflow that automatically preserves source/derivative boundaries, auditable lineage, fixity, and disclosure controls on real archaeology-relevant data streams.

We demonstrate the workflow on three live public endpoints (NYC Archaeology Reports Database, Cleveland Museum of Art Open Access API, and Art Institute of Chicago API), processing 687 records in deterministic mode and 36 records (72 LLM calls) in real-LLM mode using Qwen 2.5 Coder (1.5B). Provenance mode achieved perfect fixity, lineage completeness, and audit detection across both deterministic and stochastic transformations, while naive summarization retained zero explicit provenance. The method is offered as a practical, reproducible tool for archaeologists who need trustworthy AI-assisted analysis.
\end{abstract}

\noindent\textbf{Keywords:} digital archaeology; archaeological method; provenance; evidentiary integrity; reproducibility; generative AI; digital heritage

\section{Introduction}
On an archaeological excavation, every layer of soil is carefully labeled so future researchers can trace a single artifact back to its exact context. The same principle now applies to the digital records we rely on: excavation reports, museum APIs, and open repositories. When archaeologists use large language models or other AI tools to summarize these records at scale, outputs often return as clean prose with no visible connection to source evidence.

Silicon Stratigraphy is a lightweight provenance-first workflow designed to prevent that loss. It attaches four explicit metadata fields to each derivative record (\emph{generated\_label}, \emph{generated\_by}, \emph{generated\_at}, and \emph{parent\_sha256}) while preserving mandatory context fields from the original stream. The result is a digital stratigraphy that remains auditable after transformation.

This paper addresses the problem as a methodological requirement for archaeological interpretation, not as an abstract digital-heritage objective.

\section{Archaeological Research Questions}
The manuscript addresses three archaeology-led research questions:

\begin{enumerate}
\item \textbf{RQ1}: How does provenance failure in AI-mediated digital toolchains skew interpretation of archaeological evidence (for example excavation documentation, artifact catalogues, and archival images)?
\item \textbf{RQ2}: What minimum controls should archaeologists implement so AI-assisted transformations remain auditable and source-distinguishable?
\item \textbf{RQ3}: Can a provenance-first workflow preserve practical AI utility while improving interpretive fidelity and reproducibility in archaeological reporting?
\end{enumerate}

The contribution is a full workflow and evaluation model that can be used by archaeological projects, museum teams, and digital research groups without prohibiting AI tools.

\section{Background and Standards}
The framework builds on established standards and reproducibility literature:

\begin{enumerate}
\item \textbf{OAIS} defines ingest, archival storage, data management, and dissemination responsibilities for long-term digital preservation \cite{oais}.
\item \textbf{Memento (RFC 7089)} supports datetime-based retrieval of prior web resource states, which is critical for time-specific archaeological citation \cite{memento}.
\item \textbf{PROV-O} provides a machine-readable model for entities, activities, and agents in transformation lineages \cite{provo}.
\item \textbf{Archaeological open-data and reproducibility work} emphasizes inspectable and rerunnable evidence paths \cite{kansa2012, marwick2017}.
\item \textbf{AI governance guidance} emphasizes transparency, accountability, and risk management in automated systems \cite{unesco, nist}.
\end{enumerate}

Silicon Stratigraphy operationalizes these components in archaeology-specific workflows.

\section{Archaeological Case-Study Data Design}
To match archaeology-focused scope, this manuscript defines and executes three case-study streams aligned with common archaeological practice. All values below are derived from reproducible retrieval and processing scripts run on 19 February 2026 (UTC).

\subsection{Case Stream A: Excavation Logs and Artifact Catalogues}
\textbf{Data class}: digitized trench notebooks, context sheets, locus descriptions, finds registers, and catalogue exports.\\
\textbf{Primary risk}: AI summarization or normalization can flatten stratigraphic qualifiers, uncertainty language, and local terminology.\\
\textbf{Required reporting fields}:
\begin{itemize}
\item Project/site identifier: New York City Landmarks Preservation Commission Archaeology Reports Database (Socrata dataset ID \texttt{fuzb-9jre}, source endpoint \url{https://data.cityofnewyork.us/resource/fuzb-9jre.json}).
\item Date range of sampled source records: 1973--2015 (from the \textit{date} field in the extended run).
\item Record count and file types: 300 source records, JSON format; normalized source fields were \texttt{biblioid}, \texttt{borough}, \texttt{author}, \texttt{date}, \texttt{title}, and \texttt{report\_abstract}.
\item Transformation tools used: deterministic baseline and provenance transforms implemented in \texttt{run\_provenance\_extended\_validation.py} (labels: \texttt{summary} baseline and \texttt{deterministic\_transform\_v2} provenance mode).
\end{itemize}

\subsection{Case Stream B: Museum and Collection Documentation}
\textbf{Data class}: accession records, object metadata, conservation notes, and archival photographs.\\
\textbf{Primary risk}: AI enhancement or metadata generation can introduce stylistic certainty or object traits not present in primary records.\\
\textbf{Required reporting fields}:
\begin{itemize}
\item Institution/collection: Cleveland Museum of Art Open Access API. Endpoint: \url{https://openaccess-api.clevelandart.org/api/artworks/}.
\item Object classes sampled: 196 deduplicated records queried from ancient-relevant terms (\texttt{roman}, \texttt{egyptian}); sampled departments included Greek and Roman Art and Egyptian and Ancient Near Eastern Art, with additional records returned by API indexing.
\item Image/metadata transformations audited: source metadata to summary-only derivative (naive mode) versus provenance-first derivative preserving mandatory context keys (\texttt{objectID}, \texttt{department}, \texttt{title}, \texttt{culture}, \texttt{objectDate}, \texttt{accessionNumber}).
\item Validation protocol in this run: machine-auditable metadata retention and lineage checks; no institution-side curatorial adjudication was claimed for this experiment.
\end{itemize}

\subsection{Case Stream C: Contemporary Field or Public Portal Pipeline}
\textbf{Data class}: public-facing museum portal/API records and AI-assisted labels/summaries.\\
\textbf{Primary risk}: generated explanatory layers can be mistaken for field observations in downstream interpretation.\\
\textbf{Required reporting fields}:
\begin{itemize}
\item Field project or portal: Art Institute of Chicago public API search endpoint (\url{https://api.artic.edu/api/v1/artworks/search}).
\item Data products evaluated: 191 deduplicated records from roman/egyptian queries using fields \texttt{id}, \texttt{title}, \texttt{date\_display}, \texttt{place\_of\_origin}, and \texttt{main\_reference\_number}.
\item AI-mediated layers generated in this experiment: deterministic derivative summaries for each sampled record to emulate accelerated interpretation outputs.
\item Disclosure and audit interface: explicit derivative labeling (\texttt{generated\_label}), parent linkage (\texttt{parent\_sha256}), and run-level supplementary reporting.
\end{itemize}

\subsection{Data Governance Across All Case Streams}
All case streams should document:
\begin{enumerate}
\item legal and ethical basis for data handling,
\item provenance retention policy,
\item role-level permissions for source versus derivative editing,
\item public disclosure language distinguishing evidence from generated interpretation.
\end{enumerate}

\section{Silicon Stratigraphy Framework}
\subsection{Layer Model}
The method adapts archaeological stratigraphic logic to digital evidence:

\begin{enumerate}
\item \textbf{Source Layer}: primary archaeological records as originally captured or digitized.
\item \textbf{Preservation Layer}: fixity, timestamp, and replication artifacts that stabilize source state.
\item \textbf{Derivative Layer}: AI-assisted outputs (summaries, classifications, translations, renderings).
\item \textbf{Interpretive Layer}: published claims, arguments, and narratives that must reference both source and derivative lineage.
\end{enumerate}

\subsection{Preservation Invariants}
Each evidence object is documented using five practical invariants:
\begin{enumerate}
\item byte-level artifact package,
\item SHA-256 digest and file metadata,
\item trusted timestamp anchor,
\item execution-context metadata (software toolchain and model/version where relevant),
\item lineage edges linking parent and derivative objects.
\end{enumerate}

\subsection{Operational Pipeline}
\begin{table}[htbp]
\centering
\caption{Silicon Stratigraphy operational pipeline for archaeological records}
\label{tab:pipeline}
\begin{tabular}{p{0.17\textwidth}p{0.39\textwidth}p{0.34\textwidth}}
\toprule
\textbf{Stage} & \textbf{Action} & \textbf{Output} \\
\midrule
Acquire & Capture source objects with context metadata (origin, datetime, operator, format, project IDs) & Source package + manifest \\
Fixity & Compute digest and file-level checks & Fixity register \\
Anchor & Record digest commitments to immutable timestamped log & Anchor event record \\
Replicate & Store in independent repositories (for example institutional + offline copy) & Redundancy attestations \\
Transform & Record AI or software transformation (tool, version, parameters, prompt when relevant) & Lineage event \\
Audit & Re-run fixity and lineage completeness checks on schedule & Audit report + exceptions \\
\bottomrule
\end{tabular}
\end{table}

\section{Archaeology-Specific Outcomes and Evaluation Criteria}
Evaluation is tied to archaeological interpretation, not generic system throughput.

\begin{longtable}{p{0.26\textwidth}p{0.28\textwidth}p{0.36\textwidth}}
\caption{Evaluation criteria for archaeological interpretive fidelity}\\
\toprule
\textbf{Criterion} & \textbf{How to Measure} & \textbf{Interpretive Relevance} \\
\midrule
\endfirsthead
\toprule
\textbf{Criterion} & \textbf{How to Measure} & \textbf{Interpretive Relevance} \\
\midrule
\endhead
Source-distinguishability & Share of derivative outputs with explicit parent pointers to source records & Prevents derivatives from being cited as primary evidence \\
Context retention & Presence of key contextual markers (context IDs, provenience fields, uncertainty qualifiers) before and after transformation & Protects stratigraphic and contextual meaning \\
Lineage completeness & Proportion of transformation steps recorded with tool/version metadata & Enables third-party audit and rerun \\
Fixity stability & Scheduled re-hash checks with no unexplained drift & Supports integrity and chain-of-custody confidence \\
Disclosure clarity & Human-review scoring of whether interfaces clearly label generated content & Reduces interpretive confusion in publication and public dissemination \\
Reproducibility & Independent team ability to reconstruct claim-to-source pathway & Tests archaeological argument robustness \\
\bottomrule
\end{longtable}

Projects should define pass thresholds per criterion before deployment and report exceptions explicitly.

\section{Experiment Execution and Results}
Three streams were executed with live retrieval and deterministic reproducibility controls. Full machine-readable outputs are archived in the supplementary materials and at the project repository:
\begin{center}
\url{https://github.com/Scottcjn/echoes-silicon-age-bridge}
\end{center}
\noindent commit \texttt{0c1bf0f}.
\begin{itemize}
\item \texttt{extended\_provenance\_validation\_results.json}
\item \texttt{extended\_provenance\_validation\_report.md}
\end{itemize}

The total evaluated corpus in the extended run was 687 records (300 NYC archaeology-report records, 196 Cleveland Museum records, 191 Art Institute of Chicago records). Table \ref{tab:results} summarizes key measured outcomes comparing a naive derivative mode against a provenance-first mode.

\begin{table}[htbp]
\centering
\caption{Measured outcomes from the 2026-02-19 extended validation run}
\label{tab:results}
\small
\setlength{\tabcolsep}{4pt}
\begin{tabular}{p{0.23\textwidth}p{0.10\textwidth}p{0.11\textwidth}p{0.11\textwidth}p{0.11\textwidth}p{0.11\textwidth}}
\toprule
\textbf{Stream} & \textbf{Records} & \textbf{Fixity Stability} & \textbf{Context (Prov)} & \textbf{Lineage (Prov)} & \textbf{Tamper Recall} \\
\midrule
NYC archaeology reports & 300 & 1.000 & 0.999 & 1.000 & 1.000 \\
Cleveland museum records & 196 & 1.000 & 1.000 & 1.000 & 1.000 \\
AIC museum records & 191 & 1.000 & 1.000 & 1.000 & 1.000 \\
\bottomrule
\end{tabular}
\end{table}

Across all three streams in the extended run, provenance-first mode produced:
\begin{enumerate}
\item source-distinguishability rate = 1.000,
\item lineage completeness rate = 1.000,
\item disclosure label rate = 1.000,
\item reproducible root-hash verification = true in all streams.
\end{enumerate}

In contrast, the naive mode produced zero explicit parent linkage and zero lineage completeness in this run, demonstrating the specific interpretive risk addressed by the framework.

\subsection{Real-LLM Single-Hop and Multi-Hop Validation}
To address reviewer concern that deterministic transforms may not represent live model behavior, a separate run executed real LLM transforms using a local Ollama endpoint (\url{http://127.0.0.1:11434/api/generate}) and model \texttt{Qwen 2.5 Coder (1.5B)} with CPU-forced options (\texttt{num\_gpu=0}). This run used 12 sampled records per stream (36 total) across the same three archaeology-relevant source snapshots, with 72 total LLM calls.

One-hop mode generated an LLM summary directly from source records. Two-hop mode generated a second LLM interpretation from hop-1 summaries. Naive variants omitted lineage metadata; provenance-first variants attached \texttt{generated\_label}, \texttt{generated\_by}, \texttt{generated\_at}, and parent linkage plus mandatory context fields.

\begin{table}[htbp]
\centering
\caption{Real-LLM one-hop and two-hop lineage outcomes (2026-02-19 run)}
\label{tab:llmresults}
\small
\setlength{\tabcolsep}{4pt}
\begin{tabular}{p{0.26\textwidth}p{0.10\textwidth}p{0.12\textwidth}p{0.12\textwidth}p{0.12\textwidth}p{0.12\textwidth}}
\toprule
\textbf{Stream} & \textbf{Records} & \textbf{1-Hop Naive Lineage} & \textbf{1-Hop Prov Audit Pass} & \textbf{2-Hop Naive Lineage} & \textbf{2-Hop Prov Chain Pass} \\
\midrule
NYC archaeology reports & 12 & 0.000 & 1.000 & 0.000 & 1.000 \\
Cleveland museum records & 12 & 0.000 & 1.000 & 0.000 & 1.000 \\
AIC museum records & 12 & 0.000 & 1.000 & 0.000 & 1.000 \\
\bottomrule
\end{tabular}
\end{table}

Additional two-hop fault injections (20\% records per stream) tested orphan parent links, ancestor mismatch, mandatory context erasure, and generated-label stripping. Baseline two-hop provenance had fail rate 0.000; injected scenarios had fail rate 0.167 with detection recall 1.000 and false positive rate 0.000 in all streams.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{silicon-stratigraphy-workflow-comparison.pdf}
\caption{Workflow comparison. \textbf{Top:} Naive AI summarisation detaches claims from source context and removes auditability (digital equivalent of mixed, unlabelled backfill). \textbf{Bottom:} Silicon Stratigraphy preserves clear digital layers with timestamps, generated-content labeling, and cryptographic parent linkage, allowing full traceability exactly as we do with physical stratigraphy on site.}
\label{fig:workflow}
\end{figure}

\section{Audit Failure Proof-of-Concept}
To demonstrate that the audit layer fails records when provenance constraints are broken, four additional fault scenarios were injected into provenance-mode derivatives (10\% of records per stream): orphan parent link, missing \texttt{generated\_by}, mandatory context erasure, and stripped \texttt{generated\_label}.

\begin{table}[htbp]
\centering
\caption{Injected audit-failure scenarios and observed audit outcomes}
\label{tab:auditfails}
\small
\setlength{\tabcolsep}{4pt}
\begin{tabular}{p{0.30\textwidth}p{0.14\textwidth}p{0.16\textwidth}p{0.14\textwidth}p{0.14\textwidth}}
\toprule
\textbf{Scenario} & \textbf{Injection Fraction} & \textbf{Observed Fail Rate Range} & \textbf{Recall Range} & \textbf{FP Range} \\
\midrule
Baseline provenance (no injection) & 0.00 & 0.000--0.000 & n/a & 0.000--0.000 \\
Orphan parent link & 0.10 & 0.097--0.100 & 1.000--1.000 & 0.000--0.000 \\
Missing \texttt{generated\_by} & 0.10 & 0.097--0.100 & 1.000--1.000 & 0.000--0.000 \\
Mandatory context erasure & 0.10 & 0.097--0.100 & 1.000--1.000 & 0.000--0.000 \\
Generated label stripped & 0.10 & 0.097--0.100 & 1.000--1.000 & 0.000--0.000 \\
\bottomrule
\end{tabular}
\end{table}

These results provide explicit fail-state evidence: the audit controls do not merely score records; they produce deterministic failure on broken lineage, broken disclosure, and broken context.

\section{Independent Rerun Protocol}
The validation can be independently rerun with the following protocol:
\begin{enumerate}
\item Ensure \texttt{python3} and the \texttt{requests} package are available.
\item Execute:
\begin{verbatim}
python3 run_provenance_extended_validation.py
\end{verbatim}
\item Verify output files:
\begin{verbatim}
results/extended_provenance_validation_results.json
results/extended_provenance_validation_report.md
\end{verbatim}
\item Confirm key expectations in the report:
\begin{verbatim}
- baseline_provenance fail rate = 0.000
- injected scenarios fail rate ~= 0.10
- detection recall = 1.000
- false positive rate = 0.000
\end{verbatim}
\end{enumerate}

\section{Case-Study Reporting Protocol}
For each case stream (A-C), report the following:

\begin{enumerate}
\item dataset scope and inclusion rules,
\item baseline source inventory statistics,
\item transformation inventory (manual and AI-assisted),
\item criterion-level outcomes from Table 2,
\item interpretive deviations detected and how they were resolved,
\item remaining uncertainty and unresolved provenance gaps.
\end{enumerate}

This structure keeps results comparable across projects while remaining archaeologically interpretable.

\section{Pilot Implementation Note}
A working implementation accompanies this manuscript as a proof of deployability. The implementation demonstrates:

\begin{enumerate}
\item packaging of source and derivative artifacts with manifests,
\item hash and timestamp anchoring workflow,
\item lineage recording across transformed outputs,
\item audit-ready artifact bundles for external verification.
\end{enumerate}

The implementation is presented as procedural evidence that the framework is practical. It is not presented as a universal benchmark study.

\section{Discussion}
The findings of this methods study support three practical points for archaeology:

As a field-style example, a derivative sentence such as ``Beads of Dutch origin appear frequently in Lower Manhattan contexts'' is only methodologically useful when it carries explicit provenance tags linking back to the source record and generation event. Under Silicon Stratigraphy, that sentence remains connected to its parent record via \texttt{parent\_sha256}, includes machine-generation disclosure fields, and can be audited back to the original report record before interpretive reuse.

\begin{enumerate}
\item \textbf{AI use can remain methodologically acceptable} when provenance boundaries are explicit and auditable.
\item \textbf{Interpretive reliability depends on provenance discipline}, not on whether teams use or avoid AI tools.
\item \textbf{Workflow transparency is a publication issue}, not only a technical one: provenance should be reviewable alongside argumentation.
\end{enumerate}

For journal practice, this implies that manuscripts relying on AI-mediated processing should provide source/derivative traceability at submission stage.

\section{Limitations}
This manuscript is a framework and reporting design paper with a pilot implementation. Limits include:
\begin{enumerate}
\item no multi-lab controlled replication trial in this version,
\item project-specific differences in archive structure and legal constraints,
\item transition-period records where human and machine authorship are partially entangled,
\item the real-LLM validation sample is limited (36 records; 72 calls) and should be expanded in future rounds,
\item additional labor overhead until provenance tooling is integrated into standard archaeological software stacks.
\end{enumerate}

\section{Conclusion}
Archaeological interpretation in digital environments requires a direct response to provenance failure under AI-mediated workflows. Silicon Stratigraphy provides that response through explicit source-preservation boundaries, auditable transformation lineage, and archaeology-specific evaluation criteria tied to interpretive fidelity and reproducibility.

The framework is intended for immediate application in excavation archives, museum documentation, and field-to-public digital pipelines. Its value is pragmatic: keep modern computational workflows usable while preserving the evidentiary discipline archaeological interpretation depends on.

\section*{Competing Interests}
The author leads some implementation infrastructure discussed as procedural demonstration. This manuscript is submitted as a methods contribution focused on archaeological workflow integrity.

\section*{Data and Materials Availability}
The implementation package includes manuscript artifacts, manifests, and hash records intended for independent verification. This revision also includes reproducible experiment scripts and outputs archived in the supplementary materials and at:
\begin{center}
\url{https://github.com/Scottcjn/echoes-silicon-age-bridge}
\end{center}
\noindent commit \texttt{0c1bf0f}. Source endpoints used in the run were:
\begin{enumerate}
\item NYC Archaeology Reports endpoint:\\
\url{https://data.cityofnewyork.us/resource/fuzb-9jre.json}
\item Cleveland Museum of Art Open Access endpoint:\\
\url{https://openaccess-api.clevelandart.org/api/artworks/}
\item Art Institute of Chicago API endpoint:\\
\url{https://api.artic.edu/api/v1/artworks/search}
\item Real-LLM validation outputs: supplementary results JSON and report Markdown files for the 2026-02-19 run.
\end{enumerate}

\begin{thebibliography}{99}
\bibitem{oais}
Consultative Committee for Space Data Systems (CCSDS). \textit{Reference Model for an Open Archival Information System (OAIS)}. CCSDS 650.0-M-2, June 2012.

\bibitem{memento}
Van de Sompel, H., Nelson, M. L., Sanderson, R., Balakireva, L., Ainsworth, S., and Shankar, H. RFC 7089: \textit{HTTP Framework for Time-Based Access to Resource States (Memento)}. IETF, 2013.

\bibitem{provo}
Lebo, T., Sahoo, S., and McGuinness, D. (eds.). \textit{PROV-O: The PROV Ontology}. W3C Recommendation, 30 April 2013.

\bibitem{kansa2012}
Kansa, Eric C. ``Openness and Archaeology's Information Ecosystem.'' \textit{World Archaeology} 44, no. 4 (2012): 498--520.

\bibitem{marwick2017}
Marwick, Ben. ``Computational Reproducibility in Archaeological Research: Basic Principles and a Case Study of Their Implementation.'' \textit{Journal of Archaeological Method and Theory} 24 (2017): 424--450.

\bibitem{unesco}
UNESCO. \textit{Recommendation on the Ethics of Artificial Intelligence}. 2021.

\bibitem{nist}
National Institute of Standards and Technology (NIST). \textit{Artificial Intelligence Risk Management Framework (AI RMF 1.0)}. NIST AI 100-1, 2023.

\end{thebibliography}

\end{document}
